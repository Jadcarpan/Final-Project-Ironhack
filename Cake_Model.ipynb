{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I link my database in my personal Google Drive"
      ],
      "metadata": {
        "id": "hhN_RBiOGPBe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM-dsIPCq4Zy",
        "outputId": "f59e9def-dbfa-452d-fb3a-d65664587599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnwCgo8siReH"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "img_height = 300\n",
        "img_width = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIR0kRZiI_AT",
        "outputId": "0b130cdb-8f55-4a56-a4cd-f70fdacb3262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7365 files belonging to 10 classes.\n",
            "Using 5892 files for training.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iscU3UoVJBXj",
        "outputId": "f964d53b-cc33-4c8a-815b-aac72ad11d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7365 files belonging to 10 classes.\n",
            "Using 1473 files for validation.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHAxkHX5JD3k",
        "outputId": "1a70bd0b-4da1-40ca-9f63-14204f6861f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apfelstrudel', 'bienenstich', 'donauwelle', 'eierschecke', 'frankfurter kranz', 'kaiserschmarn', 'kalter hund', 'sachertorte', 'schwarzwalder kirschtorte', 'streuselkuchen']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wacTRWkeiReT"
      },
      "outputs": [],
      "source": [
        "###This is supposed to be used only once, to eliminate all non-pictures or non-supported files of the database\n",
        "\n",
        "#from pathlib import Path\n",
        "#import imghdr\n",
        "#import os\n",
        "\n",
        "#data_dir = \"/content/drive/MyDrive/dataset\"\n",
        "#image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
        "\n",
        "#img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
        "#for filepath in Path(data_dir).rglob(\"*\"):\n",
        "#    if filepath.suffix.lower() in image_extensions:\n",
        "#        img_type = imghdr.what(filepath)\n",
        "#        if img_type is None:\n",
        "#            print(f\"{filepath} is not an image\")\n",
        "#            os.remove(filepath)\n",
        "#        elif img_type not in img_type_accepted_by_tf:\n",
        "#            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
        "#            os.remove(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-MfMoenJi8s",
        "outputId": "98b5135d-7b92-4123-bf7b-31e7dd1a92ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 300, 300, 3)\n",
            "(16,)\n"
          ]
        }
      ],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEYxo2CTJvY9"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpvNASf4Rlei"
      },
      "outputs": [],
      "source": [
        "num_classes = len(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J80BAbIMs21"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zeg8zsqXCsm"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.3),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(48, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvyAINs9ZOmJ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWLkKoKjZSoC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf595639-4cf2-4fe7-834f-7bdd42623942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 300, 300, 3)       0         \n",
            "                                                                 \n",
            " rescaling_1 (Rescaling)     (None, 300, 300, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 300, 300, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 150, 150, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 150, 150, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 75, 75, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 75, 75, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 37, 37, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 37, 37, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 43808)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 48)                2102832   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                490       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,122,714\n",
            "Trainable params: 2,122,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWS-vvNaZDag",
        "outputId": "e3812bb4-3e60-4660-e325-e70f8ac83af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "369/369 [==============================] - 1219s 689ms/step - loss: 2.0538 - accuracy: 0.2071 - val_loss: 1.8085 - val_accuracy: 0.2498\n",
            "Epoch 2/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.8126 - accuracy: 0.2899 - val_loss: 1.6957 - val_accuracy: 0.3245\n",
            "Epoch 3/50\n",
            "369/369 [==============================] - 15s 40ms/step - loss: 1.6626 - accuracy: 0.3888 - val_loss: 1.5402 - val_accuracy: 0.4406\n",
            "Epoch 4/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.5360 - accuracy: 0.4420 - val_loss: 1.4180 - val_accuracy: 0.4800\n",
            "Epoch 5/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.4348 - accuracy: 0.4810 - val_loss: 1.4091 - val_accuracy: 0.4793\n",
            "Epoch 6/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.3908 - accuracy: 0.5012 - val_loss: 1.4783 - val_accuracy: 0.4650\n",
            "Epoch 7/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.3418 - accuracy: 0.5227 - val_loss: 1.2702 - val_accuracy: 0.5485\n",
            "Epoch 8/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.2832 - accuracy: 0.5475 - val_loss: 1.2992 - val_accuracy: 0.5098\n",
            "Epoch 9/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.2551 - accuracy: 0.5611 - val_loss: 1.2569 - val_accuracy: 0.5431\n",
            "Epoch 10/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.2205 - accuracy: 0.5721 - val_loss: 1.2041 - val_accuracy: 0.5723\n",
            "Epoch 11/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.1842 - accuracy: 0.5765 - val_loss: 1.1547 - val_accuracy: 0.5872\n",
            "Epoch 12/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.1464 - accuracy: 0.5993 - val_loss: 1.1533 - val_accuracy: 0.6056\n",
            "Epoch 13/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.1059 - accuracy: 0.6237 - val_loss: 1.0512 - val_accuracy: 0.6259\n",
            "Epoch 14/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.0786 - accuracy: 0.6295 - val_loss: 1.0482 - val_accuracy: 0.6382\n",
            "Epoch 15/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.0646 - accuracy: 0.6375 - val_loss: 1.0779 - val_accuracy: 0.6348\n",
            "Epoch 16/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.0314 - accuracy: 0.6456 - val_loss: 0.9892 - val_accuracy: 0.6612\n",
            "Epoch 17/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 1.0114 - accuracy: 0.6517 - val_loss: 0.9882 - val_accuracy: 0.6701\n",
            "Epoch 18/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.9888 - accuracy: 0.6677 - val_loss: 1.1421 - val_accuracy: 0.6259\n",
            "Epoch 19/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.9613 - accuracy: 0.6787 - val_loss: 1.0112 - val_accuracy: 0.6619\n",
            "Epoch 20/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.9546 - accuracy: 0.6791 - val_loss: 1.0296 - val_accuracy: 0.6470\n",
            "Epoch 21/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.9349 - accuracy: 0.6847 - val_loss: 0.9976 - val_accuracy: 0.6477\n",
            "Epoch 22/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.9340 - accuracy: 0.6874 - val_loss: 0.9588 - val_accuracy: 0.6823\n",
            "Epoch 23/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8990 - accuracy: 0.6967 - val_loss: 0.9709 - val_accuracy: 0.6796\n",
            "Epoch 24/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8819 - accuracy: 0.7018 - val_loss: 0.8981 - val_accuracy: 0.7122\n",
            "Epoch 25/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8849 - accuracy: 0.6972 - val_loss: 0.8887 - val_accuracy: 0.7013\n",
            "Epoch 26/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8695 - accuracy: 0.7069 - val_loss: 0.9636 - val_accuracy: 0.6911\n",
            "Epoch 27/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8557 - accuracy: 0.7142 - val_loss: 0.9909 - val_accuracy: 0.6768\n",
            "Epoch 28/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8372 - accuracy: 0.7191 - val_loss: 0.8868 - val_accuracy: 0.7115\n",
            "Epoch 29/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8174 - accuracy: 0.7218 - val_loss: 0.9221 - val_accuracy: 0.6952\n",
            "Epoch 30/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8122 - accuracy: 0.7262 - val_loss: 0.8916 - val_accuracy: 0.7142\n",
            "Epoch 31/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.8062 - accuracy: 0.7346 - val_loss: 0.8831 - val_accuracy: 0.7128\n",
            "Epoch 32/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7881 - accuracy: 0.7330 - val_loss: 0.9737 - val_accuracy: 0.6911\n",
            "Epoch 33/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7767 - accuracy: 0.7339 - val_loss: 0.8645 - val_accuracy: 0.7223\n",
            "Epoch 34/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7829 - accuracy: 0.7364 - val_loss: 0.8747 - val_accuracy: 0.7020\n",
            "Epoch 35/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7684 - accuracy: 0.7432 - val_loss: 0.8656 - val_accuracy: 0.7244\n",
            "Epoch 36/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7371 - accuracy: 0.7573 - val_loss: 0.8683 - val_accuracy: 0.7271\n",
            "Epoch 37/50\n",
            "369/369 [==============================] - 15s 41ms/step - loss: 0.7294 - accuracy: 0.7581 - val_loss: 1.0005 - val_accuracy: 0.7054\n",
            "Epoch 38/50\n",
            "267/369 [====================>.........] - ETA: 3s - loss: 0.7354 - accuracy: 0.7554"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(patience=5)\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs,\n",
        "  callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dduoLfKsZVIA"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(val_acc))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtv5VbaVb-3W"
      },
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC40sRITBSsQ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "images = [\"https://cdn.lowcarb-community.de/2015/11/Donauwelle.jpg\",\"https://karls-shop.b-cdn.net/media/49/29/a6/1619182636/kuchen-bienenstich-szene1.jpg\",\"http://www.ankerbrot.at/io/produkt_img/2297.jpg\",\"https://rezepte-silkeswelt.de/wp-content/uploads/2020/02/Pudding-Streuselkuchen1-scaled-e1629386746610.jpg\"]\n",
        "\n",
        "for BS_url in images: \n",
        "  BS_path = tf.keras.utils.get_file(origin=BS_url)\n",
        "\n",
        "\n",
        "  img = tf.keras.utils.load_img(\n",
        "      BS_path, target_size=(img_height, img_width)\n",
        "  )\n",
        "  img_array = tf.keras.utils.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "  print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving normal model and saving as TensorFlow Lite for later use in Android"
      ],
      "metadata": {
        "id": "TOF2yT56GjmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr1lhyAbiRet"
      },
      "outputs": [],
      "source": [
        "model.save('model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8ySxVJubs7Q"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copia de classification.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}